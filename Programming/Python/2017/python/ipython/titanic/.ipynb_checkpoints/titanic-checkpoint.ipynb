{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Look-the-data\" data-toc-modified-id=\"Look-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Look the data</a></div><div class=\"lev1 toc-item\"><a href=\"#Visualizaton\" data-toc-modified-id=\"Visualizaton-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Visualizaton</a></div><div class=\"lev2 toc-item\"><a href=\"#Survived-vs-Sex\" data-toc-modified-id=\"Survived-vs-Sex-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Survived vs Sex</a></div><div class=\"lev2 toc-item\"><a href=\"#Survived-vs-Age\" data-toc-modified-id=\"Survived-vs-Age-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Survived vs Age</a></div><div class=\"lev2 toc-item\"><a href=\"#Survived-vs-Fare\" data-toc-modified-id=\"Survived-vs-Fare-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Survived vs Fare</a></div><div class=\"lev2 toc-item\"><a href=\"#Fare-vs-Pclass\" data-toc-modified-id=\"Fare-vs-Pclass-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Fare vs Pclass</a></div><div class=\"lev2 toc-item\"><a href=\"#Survived-vs-Embarked\" data-toc-modified-id=\"Survived-vs-Embarked-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Survived vs Embarked</a></div><div class=\"lev1 toc-item\"><a href=\"#Data-Manipulation\" data-toc-modified-id=\"Data-Manipulation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Manipulation</a></div><div class=\"lev2 toc-item\"><a href=\"#Status-function\" data-toc-modified-id=\"Status-function-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Status function</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Load the data</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-New-Attribute-Titles\" data-toc-modified-id=\"Create-New-Attribute-Titles-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Create New Attribute Titles</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Age\" data-toc-modified-id=\"Process-Age-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Process Age</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Name\" data-toc-modified-id=\"Process-Name-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Process Name</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Fare\" data-toc-modified-id=\"Process-Fare-36\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Process Fare</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Embarked\" data-toc-modified-id=\"Process-Embarked-37\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Process Embarked</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Cabin\" data-toc-modified-id=\"Process-Cabin-38\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Process Cabin</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Sex\" data-toc-modified-id=\"Process-Sex-39\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Process Sex</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Pclass\" data-toc-modified-id=\"Process-Pclass-310\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>Process Pclass</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Ticket\" data-toc-modified-id=\"Process-Ticket-311\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;</span>Process Ticket</a></div><div class=\"lev2 toc-item\"><a href=\"#Process-Family\" data-toc-modified-id=\"Process-Family-312\"><span class=\"toc-item-num\">3.12&nbsp;&nbsp;</span>Process Family</a></div><div class=\"lev1 toc-item\"><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modelling</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Required-Libraries\" data-toc-modified-id=\"Import-Required-Libraries-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Import Required Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Compute-Score\" data-toc-modified-id=\"Compute-Score-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Compute Score</a></div><div class=\"lev2 toc-item\"><a href=\"#Recover-Train-Test-Target\" data-toc-modified-id=\"Recover-Train-Test-Target-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Recover Train Test Target</a></div><div class=\"lev2 toc-item\"><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Feature Selection</a></div><div class=\"lev2 toc-item\"><a href=\"#Hyperparameters-Tuning\" data-toc-modified-id=\"Hyperparameters-Tuning-45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Hyperparameters Tuning</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ---\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.shape\n",
    "data.head()\n",
    "data.describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are only 714 age, fill missing values by median\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "data.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survived vs Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_sex = data[data['Survived']==1]['Sex'].value_counts()\n",
    "dead_sex = data[data['Survived']==0]['Sex'].value_counts()\n",
    "df = pd.DataFrame([survived_sex,dead_sex])\n",
    "df.index = ['Survived','Dead']\n",
    "# df.plot(kind='bar',stacked=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survived vs Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([ data[data['Survived']==1]['Age'], \n",
    "           data[data['Survived']==0]['Age']\n",
    "         ], \n",
    "         stacked=True, \n",
    "         color = ['g','r'],\n",
    "         bins = 30,\n",
    "         label = ['Survived','Dead'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survived vs Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "ax = plt.subplot()\n",
    "ax.scatter(data[data['Survived']==1]['Age'],data[data['Survived']==1]['Fare'],c='green',s=40)\n",
    "ax.scatter(data[data['Survived']==0]['Age'],data[data['Survived']==0]['Fare'],c='red',s=40)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Fare')\n",
    "ax.legend(('survived','dead'),scatterpoints=1,loc='upper right',fontsize=15,)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare vs Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "ax.set_ylabel('Average fare')\n",
    "data.groupby('Pclass').mean()['Fare'].plot(kind='bar',figsize=(15,8), ax = ax)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survived vs Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_embark = data[data['Survived']==1]['Embarked'].value_counts()\n",
    "dead_embark = data[data['Survived']==0]['Embarked'].value_counts()\n",
    "df = pd.DataFrame([survived_embark,dead_embark])\n",
    "df.index = ['Survived','Dead']\n",
    "df.plot(kind='bar', stacked=True, figsize=(15,8))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a print function that asserts whether or not a feature has been processed.\n",
    "def status(feature):\n",
    "    print ('Processing',feature,': ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    train = pd.read_csv('train.csv')\n",
    "    \n",
    "    # reading test data\n",
    "    test = pd.read_csv('test.csv')\n",
    "\n",
    "    # extracting and then removing the targets from the training data \n",
    "    targets = train.Survived\n",
    "    train.drop('Survived', 1, inplace=True)\n",
    "    \n",
    "\n",
    "    # merging train data and test data for future feature engineering\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop('index', inplace=True, axis=1)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 11)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = get_combined_data()\n",
    "combined.describe()\n",
    "combined.head()\n",
    "combined.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Attribute Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_titles():\n",
    "\n",
    "    global combined\n",
    "    \n",
    "    # we extract the title from each name\n",
    "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "    \n",
    "    # a map of more aggregated titles\n",
    "    Title_Dictionary = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royalty\",\n",
    "                        \"Don\":        \"Royalty\",\n",
    "                        \"Sir\" :       \"Royalty\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"the Countess\":\"Royalty\",\n",
    "                        \"Dona\":       \"Royalty\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                        }\n",
    "    \n",
    "    # we map each title\n",
    "    combined['Title'] = combined.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_titles()\n",
    "combined.head()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_train = combined.head(891).groupby(['Sex','Pclass','Title'])\n",
    "grouped_median_train = grouped_train.median()\n",
    "\n",
    "grouped_test = combined.iloc[891:].groupby(['Sex','Pclass','Title'])\n",
    "grouped_median_test = grouped_test.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_median_train\n",
    "grouped_median_test\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_age():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # a function that fills the missing values of the Age variable\n",
    "    \n",
    "    def fillAges(row, grouped_median):\n",
    "        if row['Sex']=='female' and row['Pclass'] == 1:\n",
    "            if row['Title'] == 'Miss':\n",
    "                return grouped_median.loc['female', 1, 'Miss']['Age']\n",
    "            elif row['Title'] == 'Mrs':\n",
    "                return grouped_median.loc['female', 1, 'Mrs']['Age']\n",
    "            elif row['Title'] == 'Officer':\n",
    "                return grouped_median.loc['female', 1, 'Officer']['Age']\n",
    "            elif row['Title'] == 'Royalty':\n",
    "                return grouped_median.loc['female', 1, 'Royalty']['Age']\n",
    "\n",
    "        elif row['Sex']=='female' and row['Pclass'] == 2:\n",
    "            if row['Title'] == 'Miss':\n",
    "                return grouped_median.loc['female', 2, 'Miss']['Age']\n",
    "            elif row['Title'] == 'Mrs':\n",
    "                return grouped_median.loc['female', 2, 'Mrs']['Age']\n",
    "\n",
    "        elif row['Sex']=='female' and row['Pclass'] == 3:\n",
    "            if row['Title'] == 'Miss':\n",
    "                return grouped_median.loc['female', 3, 'Miss']['Age']\n",
    "            elif row['Title'] == 'Mrs':\n",
    "                return grouped_median.loc['female', 3, 'Mrs']['Age']\n",
    "\n",
    "        elif row['Sex']=='male' and row['Pclass'] == 1:\n",
    "            if row['Title'] == 'Master':\n",
    "                return grouped_median.loc['male', 1, 'Master']['Age']\n",
    "            elif row['Title'] == 'Mr':\n",
    "                return grouped_median.loc['male', 1, 'Mr']['Age']\n",
    "            elif row['Title'] == 'Officer':\n",
    "                return grouped_median.loc['male', 1, 'Officer']['Age']\n",
    "            elif row['Title'] == 'Royalty':\n",
    "                return grouped_median.loc['male', 1, 'Royalty']['Age']\n",
    "\n",
    "        elif row['Sex']=='male' and row['Pclass'] == 2:\n",
    "            if row['Title'] == 'Master':\n",
    "                return grouped_median.loc['male', 2, 'Master']['Age']\n",
    "            elif row['Title'] == 'Mr':\n",
    "                return grouped_median.loc['male', 2, 'Mr']['Age']\n",
    "            elif row['Title'] == 'Officer':\n",
    "                return grouped_median.loc['male', 2, 'Officer']['Age']\n",
    "\n",
    "        elif row['Sex']=='male' and row['Pclass'] == 3:\n",
    "            if row['Title'] == 'Master':\n",
    "                return grouped_median.loc['male', 3, 'Master']['Age']\n",
    "            elif row['Title'] == 'Mr':\n",
    "                return grouped_median.loc['male', 3, 'Mr']['Age']\n",
    "    \n",
    "    combined.head(891).Age = combined.head(891).apply(lambda r : fillAges(r, grouped_median_train) if np.isnan(r['Age']) \n",
    "                                                      else r['Age'], axis=1)\n",
    "    \n",
    "    combined.iloc[891:].Age = combined.iloc[891:].apply(lambda r : fillAges(r, grouped_median_test) if np.isnan(r['Age']) \n",
    "                                                      else r['Age'], axis=1)\n",
    "    \n",
    "    status('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing age : ok\n"
     ]
    }
   ],
   "source": [
    "process_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Name           1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "Age            1309 non-null float64\n",
      "SibSp          1309 non-null int64\n",
      "Parch          1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Title          1309 non-null object\n",
      "dtypes: float64(2), int64(4), object(6)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_names():\n",
    "    \n",
    "    global combined\n",
    "    # we clean the Name variable\n",
    "    combined.drop('Name',axis=1,inplace=True)\n",
    "    \n",
    "    # encoding in dummy variable\n",
    "    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n",
    "    combined = pd.concat([combined,titles_dummies],axis=1)\n",
    "    \n",
    "    # removing the title variable\n",
    "    combined.drop('Title',axis=1,inplace=True)\n",
    "    \n",
    "    status('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing age : ok\n",
      "Processing names : ok\n"
     ]
    }
   ],
   "source": [
    "combined = get_combined_data()\n",
    "get_titles()\n",
    "process_age()\n",
    "process_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fares():\n",
    "    \n",
    "    global combined\n",
    "    # there's one missing fare value - replacing it with the mean.\n",
    "    combined.head(891).Fare.fillna(combined.head(891).Fare.mean(), inplace=True)\n",
    "    combined.iloc[891:].Fare.fillna(combined.iloc[891:].Fare.mean(), inplace=True)\n",
    "    \n",
    "    status('fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fare : ok\n"
     ]
    }
   ],
   "source": [
    "process_fares()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_embarked():\n",
    "    \n",
    "    global combined\n",
    "    # two missing embarked values - filling them with the most frequent one (S)\n",
    "    combined.head(891).Embarked.fillna('S', inplace=True)\n",
    "    combined.iloc[891:].Embarked.fillna('S', inplace=True)\n",
    "    \n",
    "    \n",
    "    # dummy encoding \n",
    "    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n",
    "    combined = pd.concat([combined,embarked_dummies],axis=1)\n",
    "    combined.drop('Embarked',axis=1,inplace=True)\n",
    "    \n",
    "    status('embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing embarked : ok\n"
     ]
    }
   ],
   "source": [
    "process_embarked()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_cabin():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # replacing missing cabins with U (for Uknown)\n",
    "    combined.Cabin.fillna('U', inplace=True)\n",
    "    \n",
    "    # mapping each Cabin value with the cabin letter\n",
    "    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n",
    "    \n",
    "    # dummy encoding ...\n",
    "    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')\n",
    "    \n",
    "    combined = pd.concat([combined,cabin_dummies], axis=1)\n",
    "    \n",
    "    combined.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "    status('cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cabin : ok\n"
     ]
    }
   ],
   "source": [
    "process_cabin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 26 columns):\n",
      "PassengerId      1309 non-null int64\n",
      "Pclass           1309 non-null int64\n",
      "Sex              1309 non-null object\n",
      "Age              1309 non-null float64\n",
      "SibSp            1309 non-null int64\n",
      "Parch            1309 non-null int64\n",
      "Ticket           1309 non-null object\n",
      "Fare             1309 non-null float64\n",
      "Title_Master     1309 non-null uint8\n",
      "Title_Miss       1309 non-null uint8\n",
      "Title_Mr         1309 non-null uint8\n",
      "Title_Mrs        1309 non-null uint8\n",
      "Title_Officer    1309 non-null uint8\n",
      "Title_Royalty    1309 non-null uint8\n",
      "Embarked_C       1309 non-null uint8\n",
      "Embarked_Q       1309 non-null uint8\n",
      "Embarked_S       1309 non-null uint8\n",
      "Cabin_A          1309 non-null uint8\n",
      "Cabin_B          1309 non-null uint8\n",
      "Cabin_C          1309 non-null uint8\n",
      "Cabin_D          1309 non-null uint8\n",
      "Cabin_E          1309 non-null uint8\n",
      "Cabin_F          1309 non-null uint8\n",
      "Cabin_G          1309 non-null uint8\n",
      "Cabin_T          1309 non-null uint8\n",
      "Cabin_U          1309 non-null uint8\n",
      "dtypes: float64(2), int64(4), object(2), uint8(18)\n",
      "memory usage: 104.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
       "0            1       3    male  22.0      1      0         A/5 21171   7.2500   \n",
       "1            2       1  female  38.0      1      0          PC 17599  71.2833   \n",
       "2            3       3  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
       "3            4       1  female  35.0      1      0            113803  53.1000   \n",
       "4            5       3    male  35.0      0      0            373450   8.0500   \n",
       "\n",
       "   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Officer  \\\n",
       "0             0           0         1          0              0   \n",
       "1             0           0         0          1              0   \n",
       "2             0           1         0          0              0   \n",
       "3             0           0         0          1              0   \n",
       "4             0           0         1          0              0   \n",
       "\n",
       "   Title_Royalty  Embarked_C  Embarked_Q  Embarked_S  Cabin_A  Cabin_B  \\\n",
       "0              0           0           0           1        0        0   \n",
       "1              0           1           0           0        0        0   \n",
       "2              0           0           0           1        0        0   \n",
       "3              0           0           0           1        0        0   \n",
       "4              0           0           0           1        0        0   \n",
       "\n",
       "   Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  Cabin_U  \n",
       "0        0        0        0        0        0        0        1  \n",
       "1        1        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        1  \n",
       "3        1        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        1  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.info()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sex():\n",
    "    \n",
    "    global combined\n",
    "    # mapping string values to numerical one \n",
    "    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})\n",
    "    \n",
    "    status('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sex : ok\n"
     ]
    }
   ],
   "source": [
    "process_sex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_pclass():\n",
    "    \n",
    "    global combined\n",
    "    # encoding into 3 categories:\n",
    "    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n",
    "    \n",
    "    # adding dummy variables\n",
    "    combined = pd.concat([combined,pclass_dummies],axis=1)\n",
    "    \n",
    "    # removing \"Pclass\"\n",
    "    \n",
    "    combined.drop('Pclass',axis=1,inplace=True)\n",
    "    \n",
    "    status('pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pclass : ok\n"
     ]
    }
   ],
   "source": [
    "process_pclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_ticket():\n",
    "    \n",
    "    global combined\n",
    "    \n",
    "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
    "    def cleanTicket(ticket):\n",
    "        ticket = ticket.replace('.','')\n",
    "        ticket = ticket.replace('/','')\n",
    "        ticket = ticket.split()\n",
    "        ticket = list(map(lambda t : t.strip(), ticket))\n",
    "        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "        if len(ticket) > 0:\n",
    "            return ticket[0]\n",
    "        else: \n",
    "            return 'XXX'\n",
    "    \n",
    "\n",
    "    # Extracting dummy variables from tickets:\n",
    "\n",
    "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
    "    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')\n",
    "    combined = pd.concat([combined, tickets_dummies], axis=1)\n",
    "    combined.drop('Ticket', inplace=True, axis=1)\n",
    "\n",
    "    status('ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ticket : ok\n"
     ]
    }
   ],
   "source": [
    "process_ticket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_family():\n",
    "    \n",
    "    global combined\n",
    "    # introducing a new feature : the size of families (including the passenger)\n",
    "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n",
    "    \n",
    "    # introducing other features based on the family size\n",
    "    combined['Singleton'] = combined['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n",
    "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s: 1 if 2<=s<=4 else 0)\n",
    "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s: 1 if 5<=s else 0)\n",
    "    \n",
    "    status('family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family : ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_family()\n",
    "combined.shape\n",
    "combined.head()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score(clf, X, y, scoring='accuracy'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n",
    "    return np.mean(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover Train Test Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recover_train_test_target():\n",
    "    global combined\n",
    "    \n",
    "    train0 = pd.read_csv('train.csv')\n",
    "    \n",
    "    targets = train0.Survived\n",
    "    train = combined.head(891)\n",
    "    test = combined.iloc[891:]\n",
    "    \n",
    "    return train, test, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, targets = recover_train_test_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n",
    "clf = clf.fit(train, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = train.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.plot(kind='barh', figsize=(20, 20))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 14)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_reduced = model.transform(train)\n",
    "train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 14)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reduced = model.transform(test)\n",
    "test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn run_gs to True if you want to run the gridsearch again.\n",
    "run_gs = False\n",
    "\n",
    "if run_gs:\n",
    "    parameter_grid = {\n",
    "                 'max_depth' : [4, 6, 8],\n",
    "                 'n_estimators': [50, 10],\n",
    "                 'max_features': ['sqrt', 'auto', 'log2'],\n",
    "                 'min_samples_split': [1, 3, 10],\n",
    "                 'min_samples_leaf': [1, 3, 10],\n",
    "                 'bootstrap': [True, False],\n",
    "                 }\n",
    "    forest = RandomForestClassifier()\n",
    "    cross_validation = StratifiedKFold(targets, n_folds=5)\n",
    "\n",
    "    grid_search = GridSearchCV(forest,\n",
    "                               scoring='accuracy',\n",
    "                               param_grid=parameter_grid,\n",
    "                               cv=cross_validation)\n",
    "\n",
    "    grid_search.fit(train, targets)\n",
    "    model = grid_search\n",
    "    parameters = grid_search.best_params_\n",
    "\n",
    "    print('Best score: {}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "else: \n",
    "    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n",
    "                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n",
    "    \n",
    "    model = RandomForestClassifier(**parameters)\n",
    "    model.fit(train, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81266528287420281"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(model, train, targets, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model.predict(test).astype(int)\n",
    "df_output = pd.DataFrame()\n",
    "aux = pd.read_csv('test.csv')\n",
    "df_output['PassengerId'] = aux['PassengerId']\n",
    "df_output['Survived'] = output\n",
    "df_output[['PassengerId','Survived']].to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "393px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
